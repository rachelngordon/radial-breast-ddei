{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d589121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchkbnufft import KbNufft, KbNufftAdjoint\n",
    "import numpy as np\n",
    "import h5py\n",
    "from einops import rearrange\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059e2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialDCLayerSingleCoil(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        im_size,\n",
    "        grid_size,\n",
    "        lambda_init: float = np.log(np.exp(1) - 1.0) / 1.0,\n",
    "        learnable: bool = True,\n",
    "        device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.lambda_ = nn.Parameter(torch.ones(1) * lambda_init, requires_grad=learnable).to(device)\n",
    "\n",
    "        # Forward NUFFT and adjoint (no smaps)\n",
    "        self.nufft_op   = KbNufft(im_size=im_size, grid_size=grid_size).to(device)\n",
    "        self.adjnufft_op = KbNufftAdjoint(im_size=im_size, grid_size=grid_size).to(device)\n",
    "\n",
    "    def forward(self, x, y_radial, ktraj):\n",
    "        \"\"\"\n",
    "        x: (batch, 1, H, W, 2) real\n",
    "        y_radial: (n_samples, n_spokes, 2) real\n",
    "        ktraj: (1, 2, n_samples*n_spokes) float\n",
    "        \"\"\"\n",
    "        # x_c = x.to(dtype=torch.complex64)\n",
    "\n",
    "        # (1) Forward NUFFT (no smaps => single‐coil)\n",
    "        A_x = self.nufft_op(x.contiguous(), ktraj.contiguous(), smaps=None, norm='ortho')  # (batch, 1, n_samples*n_spokes, 2)\n",
    "\n",
    "        # reshape simulated k-space\n",
    "        A_x = rearrange(A_x, \"b c r i -> b c i r \")#.to(dtype)\n",
    "        A_x = torch.reshape(A_x, (1, 1, 2, 288, 640, 1)).squeeze()\n",
    "        A_x = rearrange(A_x, 'i sp sam -> sam sp i')\n",
    "\n",
    "        # (2) Weighted combine\n",
    "        lambda_c = torch.sigmoid(self.lambda_).type(torch.complex64)\n",
    "        k_dc = lambda_c * A_x + (1 - lambda_c) * y_radial\n",
    "\n",
    "        # (3) Adjoint NUFFT\n",
    "        x_dc = self.adjnufft_op(k_dc, ktraj, smaps=None, norm='ortho')  # (batch, 1, H, W)\n",
    "        return x_dc\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f\"lambda (raw)={self.lambda_.item():.4g}, learnable={self.lambda_.requires_grad}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3fc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ktraj(N_spokes, N_time, base_res, device):\n",
    "    \"\"\"\n",
    "    Precompute k-space trajectory for efficiency.\n",
    "    \"\"\"\n",
    "    N_tot_spokes = N_spokes * N_time\n",
    "    N_samples = base_res * 2\n",
    "\n",
    "    base_lin = torch.arange(N_samples, dtype=torch.float32).to(device) - base_res\n",
    "    tau = 0.5 * (1 + 5**0.5)\n",
    "    base_rad = torch.pi / (1 + tau - 1)\n",
    "    base_rot = torch.arange(N_tot_spokes, dtype=torch.float32).to(device) * base_rad\n",
    "\n",
    "    traj_x = torch.cos(base_rot).unsqueeze(1) @ base_lin.unsqueeze(0)\n",
    "    traj_y = torch.sin(base_rot).unsqueeze(1) @ base_lin.unsqueeze(0)\n",
    "    traj = torch.stack([traj_x, traj_y], dim=-1) / 2  # Shape: (N_tot_spokes, N_samples, 2)\n",
    "\n",
    "    # reshape the trajectory to be compatible with torchkbnufft\n",
    "    traj = traj.reshape(N_time, N_spokes * N_samples, 2)#.transpose(1, 0, 2)\n",
    "    # traj = rearrange(traj, 't len i -> t i len')\n",
    "    traj = rearrange(traj, 't len i -> len t i')\n",
    "    \n",
    "    # normalize\n",
    "    # traj /= torch.mean(torch.abs(traj))\n",
    "\n",
    "    traj = traj*torch.tensor([1, -1]).to(device)\n",
    "\n",
    "    traj = rearrange(traj, \"len t i -> t i len\")  # shape: (2, N_TIME, N_SPOKES)\n",
    "\n",
    "    return traj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6d8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 184320])\n"
     ]
    }
   ],
   "source": [
    "# define trajectory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "N_spokes = 288\n",
    "N_time = 1\n",
    "N_samples = 640\n",
    "\n",
    "ktraj_tensor = get_ktraj(N_spokes, N_time, N_samples // 2, device)\n",
    "print(ktraj_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47db23e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83, 16, 640, 288, 2])\n",
      "torch.Size([640, 288, 2])\n"
     ]
    }
   ],
   "source": [
    "# load k-space\n",
    "kspace_path = '/ess/scratch/scratch1/rachelgordon/fastMRI_breast_data/fastMRI_breast_IDS_001_010/fastMRI_breast_001_2.h5'\n",
    "\n",
    "f = h5py.File(kspace_path, 'r')\n",
    "original_kspace = f['kspace'][:].T\n",
    "\n",
    "original_kspace = torch.tensor(original_kspace, dtype=torch.float32)\n",
    "print(original_kspace.shape)\n",
    "\n",
    "y_radial = original_kspace[0][0]\n",
    "print(y_radial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68775bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 320, 320, 2])\n"
     ]
    }
   ],
   "source": [
    "# load image \n",
    "\n",
    "def load_nii(path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI image from the specified path.\n",
    "    Args:\n",
    "    - path (str): File path to the NIfTI image.\n",
    "    \"\"\"\n",
    "    nii_image = nib.load(path)\n",
    "    return nii_image.get_fdata()\n",
    "\n",
    "ground_truth_dir = \"/ess/scratch/scratch1/rachelgordon/complex_fully_sampled/\"\n",
    "patient_id = \"fastMRI_breast_001_1\"\n",
    "image_path = f\"{ground_truth_dir}{patient_id}/slice_040_frame_000.nii\"\n",
    "\n",
    "image = load_nii(image_path)\n",
    "image = torch.from_numpy(image)\n",
    "\n",
    "image = rearrange(image, 'i h w -> h w i').unsqueeze(0).unsqueeze(0)\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c20972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 2) Choose an image‐domain size that matches how you built the NUFFT operators.\n",
    "#    For example, if your images are 320×320:\n",
    "# ---------------------------------------------------------------------\n",
    "H = W = 320\n",
    "im_size   = (H, W)        # (coils=1, H, W) for single‐coil\n",
    "grid_size = (H * 2, W * 2)   # e.g. double‐density grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92426ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3) Build a standalone adjoint‐NUFFT operator to compare against the DC layer.\n",
    "# ---------------------------------------------------------------------\n",
    "adjnufft_op = KbNufftAdjoint(im_size=im_size, grid_size=grid_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ac9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4) Instantiate your Radial DC layer, but force λ such that sigmoid(λ)=0.\n",
    "#    For sigmoid(λ)=0 up to machine precision, you can pick raw λ = -20 (sigmoid(-20)≈2×10^(-9)).\n",
    "#    Also turn off gradient‐updates by setting requires_grad=False (so λ stays fixed).\n",
    "# ---------------------------------------------------------------------\n",
    "raw_lambda_for_zero = -20.0\n",
    "dc_layer = nn.Sequential()  # a dummy wrapper so we can set .lambda_ manually\n",
    "dc = getattr(__import__(\"__main__\"), \"RadialDCLayerSingleCoil\")(\n",
    "    im_size=im_size,\n",
    "    grid_size=grid_size,\n",
    "    lambda_init=raw_lambda_for_zero,\n",
    "    learnable=False,\n",
    "    device=torch.device(\"cuda\")\n",
    ")\n",
    "dc_layer.add_module(\"radial_dc\", dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ecae172",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_nufft/interp.py\", line 582, in sort_data\n        data_ret = torch.cat([result[2] for result in results])\n    else:\n        tm_ret, omega_ret, data_ret = sort_one_batch(tm, omega, data, grid_size)\n                                      ~~~~~~~~~~~~~~ <--- HERE\n\n    return tm_ret, omega_ret, data_ret\n  File \"/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_nufft/interp.py\", line 562, in sort_one_batch\n    _, indices = torch.sort(tmp)\n\n    return tm[:, indices], omega[:, indices], data[:, :, indices]\n                                              ~~~~~~~~~~~~~~~~~~~ <--- HERE\nRuntimeError: CUDA out of memory. Tried to allocate 506.25 GiB. GPU 0 has a total capacity of 39.49 GiB of which 38.95 GiB is free. Including non-PyTorch memory, this process has 548.00 MiB memory in use. Of the allocated memory 29.67 MiB is allocated by PyTorch, and 14.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     x_dc_from_layer \u001b[38;5;241m=\u001b[39m \u001b[43mdc_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradial_dc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_radial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_radial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mktraj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mktraj_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Direct adjoint:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     x_direct_adjoint \u001b[38;5;241m=\u001b[39m adjnufft_op(y_radial, ktraj_tensor, smaps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mortho\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m, in \u001b[0;36mRadialDCLayerSingleCoil.forward\u001b[0;34m(self, x, y_radial, ktraj)\u001b[0m\n\u001b[1;32m     36\u001b[0m k_dc \u001b[38;5;241m=\u001b[39m lambda_c \u001b[38;5;241m*\u001b[39m A_x \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lambda_c) \u001b[38;5;241m*\u001b[39m y_radial\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# (3) Adjoint NUFFT\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m x_dc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjnufft_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_dc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mktraj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mortho\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, 1, H, W)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_dc\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/modules/kbnufft.py:390\u001b[0m, in \u001b[0;36mKbNufftAdjoint.forward\u001b[0;34m(self, data, omega, interp_mats, smaps, norm)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_oversamp, Tensor)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffsets, Tensor)\n\u001b[0;32m--> 390\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mtkbnF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkb_table_nufft_adjoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaling_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43momega\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momega\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_oversamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_oversamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m smaps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(output \u001b[38;5;241m*\u001b[39m smaps\u001b[38;5;241m.\u001b[39mconj(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/functional/nufft.py:241\u001b[0m, in \u001b[0;36mkb_table_nufft_adjoint\u001b[0;34m(data, scaling_coef, im_size, grid_size, omega, tables, n_shift, numpoints, table_oversamp, offsets, norm)\u001b[0m\n\u001b[1;32m    237\u001b[0m     is_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(data)\n\u001b[1;32m    240\u001b[0m image \u001b[38;5;241m=\u001b[39m ifft_and_scale(\n\u001b[0;32m--> 241\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[43mkb_table_interp_adjoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43momega\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momega\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_oversamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_oversamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    251\u001b[0m     scaling_coef\u001b[38;5;241m=\u001b[39mscaling_coef,\n\u001b[1;32m    252\u001b[0m     im_size\u001b[38;5;241m=\u001b[39mim_size,\n\u001b[1;32m    253\u001b[0m     grid_size\u001b[38;5;241m=\u001b[39mgrid_size,\n\u001b[1;32m    254\u001b[0m     norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m    255\u001b[0m )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_complex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(image)\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/functional/interp.py:165\u001b[0m, in \u001b[0;36mkb_table_interp_adjoint\u001b[0;34m(data, omega, tables, n_shift, numpoints, table_oversamp, offsets, grid_size)\u001b[0m\n\u001b[1;32m    162\u001b[0m     is_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(data)\n\u001b[0;32m--> 165\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mKbTableInterpAdjoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momega\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_oversamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_complex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(image)\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_autograd/interp.py:142\u001b[0m, in \u001b[0;36mKbTableInterpAdjoint.forward\u001b[0;34m(ctx, data, omega, tables, n_shift, numpoints, table_oversamp, offsets, grid_size)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    136\u001b[0m     ctx, data, omega, tables, n_shift, numpoints, table_oversamp, offsets, grid_size\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply table interpolation adjoint.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    This is a wrapper for for PyTorch autograd.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtable_interp_adjoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43momega\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momega\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_oversamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_oversamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\n\u001b[1;32m    154\u001b[0m         omega, n_shift, numpoints, table_oversamp, offsets, \u001b[38;5;241m*\u001b[39mtables\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_nufft/interp.py:664\u001b[0m, in \u001b[0;36mtable_interp_adjoint\u001b[0;34m(data, omega, tables, n_shift, numpoints, table_oversamp, offsets, grid_size)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# convert to normalized freq locs and sort\u001b[39;00m\n\u001b[1;32m    663\u001b[0m tm \u001b[38;5;241m=\u001b[39m omega \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m grid_size\u001b[38;5;241m.\u001b[39mto(omega)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 664\u001b[0m tm, omega, data \u001b[38;5;241m=\u001b[39m \u001b[43msort_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momega\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_nufft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# compute interpolation centers\u001b[39;00m\n\u001b[1;32m    667\u001b[0m centers \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloor(numpoints \u001b[38;5;241m*\u001b[39m table_oversamp \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mint_type)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_nufft/interp.py\", line 582, in sort_data\n        data_ret = torch.cat([result[2] for result in results])\n    else:\n        tm_ret, omega_ret, data_ret = sort_one_batch(tm, omega, data, grid_size)\n                                      ~~~~~~~~~~~~~~ <--- HERE\n\n    return tm_ret, omega_ret, data_ret\n  File \"/gpfs/data/karczmar-lab/workspaces/rachelgordon/micromamba/envs/recon_mri/lib/python3.11/site-packages/torchkbnufft/_nufft/interp.py\", line 562, in sort_one_batch\n    _, indices = torch.sort(tmp)\n\n    return tm[:, indices], omega[:, indices], data[:, :, indices]\n                                              ~~~~~~~~~~~~~~~~~~~ <--- HERE\nRuntimeError: CUDA out of memory. Tried to allocate 506.25 GiB. GPU 0 has a total capacity of 39.49 GiB of which 38.95 GiB is free. Including non-PyTorch memory, this process has 548.00 MiB memory in use. Of the allocated memory 29.67 MiB is allocated by PyTorch, and 14.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5) Run the “pure adjoint” through your DC layer:\n",
    "# ---------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "with torch.no_grad():\n",
    "    x_dc_from_layer = dc_layer.radial_dc(\n",
    "        x=image.to(device),\n",
    "        y_radial=y_radial.to(device),\n",
    "        ktraj=ktraj_tensor.to(device)\n",
    "    )\n",
    "    # Direct adjoint:\n",
    "    x_direct_adjoint = adjnufft_op(y_radial, ktraj_tensor, smaps=None, norm='ortho')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01677914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 6) Compare the two outputs:\n",
    "# ---------------------------------------------------------------------\n",
    "# Move to CPU & convert to numpy for easy comparison:\n",
    "x1 = x_dc_from_layer.cpu().numpy()\n",
    "x2 = x_direct_adjoint.cpu().numpy()\n",
    "\n",
    "max_abs_diff = np.max(np.abs(x1 - x2))\n",
    "print(f\"Max absolute difference between DC‐layer output and direct adjoint: {max_abs_diff:.3e}\")\n",
    "\n",
    "tol = 1e-5\n",
    "if max_abs_diff < tol:\n",
    "    print(\"✅ PASS: Radial DC layer’s adjoint branch matches pure adjoint‐NUFFT.\")\n",
    "else:\n",
    "    print(\"❌ FAIL: outputs differ by more than tolerance.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recon_mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
