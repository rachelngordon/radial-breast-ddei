# Breast DCE-MRI Reconstruction Agent

This project trains a reconstruction agent for highly undersampled breast DCE-MRI using the Dynamic Diffeomorphic Equivariant Imaging (DDEI) framework. The goal is to recover diagnostic-quality temporal dynamics for cancer treatment, diagnosis, and risk prediction without requiring ground-truth images during training.

## Core Ideas
- **Unsupervised objective**: Combine a measurement consistency (MC) loss in k-space with an equivariant imaging (EI) loss in image space to enforce physics fidelity and artifact removal without paired labels (`mc.py`, `ei.py`).
- **Backbone**: LSFPNet unrolls the Low-rank + Sparsity with Framelet transform and primal–dual fixed-point optimization; includes learnable cascades, Film-style modulation, and optional low-k DC (`lsfpnet.py`, `lsfpnet_encoding.py`, `radial_lsfp.py`).
- **Flexible transforms**: EI loss supports spatial transforms (rotation, warp, subsample) and optional noise/augmentation scheduling via YAML config.

## Data & Splits
- **Dataset**: fastMRI breast DCE-MRI; 300 radial k-space scans (288 spokes, 640 samples/spoke). 83 z-partitions are zero-padded to 192 slices then FFTed to image space. The data is located at /net/scratch2/rachelgordon/zf_data_192_slices/zf_kspace. 
The sensitivity maps are in /net/scratch2/rachelgordon/zf_data_192_slices/, each within a separate directory for the patient id. Tumor segmentations for each non-DRO malignant scan are in /net/scratch2/rachelgordon/zf_data_192_slices/tumor_segmentations. The reconstructions stored in subdirectories for each patient in /net/scratch2/rachelgordon/zf_data_192_slices/ are of shape (2, 320, 320) and are complex, so they should be converted to real for plotting by np.abs(img[0]+1j*img[1])
- **Splits**: 258 train / 15 val / remainder test (`data/data_split.json`).
- **Slice strategy**: One slice/partition per scan per epoch, randomly resampled each epoch (`dataloader.py` supports `num_random_slices`).
- **Temporal setup**: 8 spokes per frame → 36 timepoints. Training draws a random 24-frame window per scan; evaluation reconstructs with a sliding window of 24 frames with 12-frame overlap.

## Training Pipeline
- **Entry point**: `train_zf.py --config <yaml> --exp_name <run_id> [--from_checkpoint true]`. Multi-GPU uses NCCL; logs, configs, checkpoints, evals stored under `output/<exp_name>/`.
- **Config example**: `configs/config_ei_no_noise_encode_both.yaml` (LSFPNet, EI on, MC weight 10, adjoint loss weight 1, Adam lr 5e-4, batch size 1, curriculum optional).
- **Loss terms**:
  - MC loss on forward NUFFT outputs (`MCLoss`).
  - EI loss on transformed reconstructions (`EILoss`); warmup and duration schedule via `model.losses.ei_loss`.
  - Optional adjoint loss and normalization (spatial, temporal, or both).
- **Transforms & physics**: NUFFT operator (`radial_lsfp.MCNUFFT`) built from k-space metadata; optional time warps, rotations, subsampling (`transform.py`).

## Evaluation
- **Metrics**: SSIM, PSNR, MSE, LPIPS (with complex-to-magnitude handling in `loss_metrics.py`), k-space MSE/MAE, and Pearson correlation of tumor enhancement curve. Validation/test use DRO-simulated ground truth for reference.
- **Sliding evaluation**: Uses chunked inference (`utils.sliding_window_inference`) with configurable chunk size/overlap (`evaluation.chunk_size`, `evaluation.chunk_overlap`).
- **Data**: Evaluation is conducted only on IDs within the DRO dataset (data/DROSubID_vs_fastMRIbreastID.csv), and is conducted for both DRO (/net/scratch2/rachelgordon/dro_dataset contains directories for DROs with different temporal resolutions, indicated by number of timeframes, which each contain the DRO image/mask, GRASP reconstruction, and simulated k-space) with ground truth and non-DRO using only raw k-space (/net/scratch2/rachelgordon/zf_data_192_slices/zf_kspace) and generated tumor segmentations (/net/scratch2/rachelgordon/zf_data_192_slices/tumor_segmentations). Both evaluations compare deep learning and GRASP reconstructions with either non-DRO or DRO data.

## Running Experiments
- **Single run**: `python3 train_zf.py --config configs/config_ei_no_noise_encode_both.yaml --exp_name <name>`.
- **Grid search**: `grid_search_batch.py` splits hyperparameter sweeps across batches; default grid searches `model.losses.adj_loss.weight` and `model.losses.ei_loss.weight`. Update `base_config_file` to an existing YAML before running. SLURM example in `grid_search.sh`.
- **Outputs**: Each run writes `eval_results/eval_metrics.csv` for downstream parsing (`parse_results` in `grid_search_batch.py`).

## Notes & Tips
- Keep `data.root_dir` and `experiment.cluster` aligned with your cluster paths; `cluster_paths.py` can rewrite paths per environment.
- For curriculum learning, adjust `training.curriculum_learning.phases` to introduce higher accelerations gradually.
- When extending transforms, ensure they operate on rearranged video tensors (see `EILoss` and `transform.py`) and preserve complex channel conventions.
